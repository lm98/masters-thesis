%! Author = leona
%! Date = 09/02/24
% !TeX root = ../thesis-main.tex

\chapter{Implementation}
\label{chap:implementation}
This chapter aims to provide an overview of important implementation choices, as well as highlight the technologies used to develop the RuFi framework.

\section{Crate Structure}
At the highest level, the framework consists of multiple \textit{library crates}. In Rust, a crate is a standalone module that can be included as a dependency inside a project via
the \texttt{cargo} package manager. There are three types of crates in Rust:

\begin{itemize}
    \item \textit{Binary crates} are crates that can be compiled into an executable.
          An example of a binary crate can be a program that runs on a device and utilizes the RuFi framework.
    \item \textit{Library crates} are crates that can be used as a dependency in other projects.
    \item \textit{Proc Macro crates} are library crates that expose procedural macros.
\end{itemize}

The development of RuFi followed a convention that is common in the Rust community for large projects, and that is the use of a \textit{workspace}.
A workspace is a directory that contains multiple Rust crates, and it is defined by a \texttt{Cargo.toml} file that lists the crates that are part of the workspace.
Apart from this detail, each crate inside the workspace is a standalone Rust project with its specific dependency management and build configuration.
In particular, there are five different library crates in the RuFi workspace:

\begin{itemize}
    \item \texttt{rf-core} contains the RuFi core implementation.
    \item \texttt{rf-distributed} contains the RuFi distributed implementation.
    \item \texttt{rf-gradient} contains the implementation of the gradient aggregate program.
    \item \texttt{rf-distributed-impl} contains an implementation for the traits defined inside rf-distributed.
    \item \texttt{rufi} has a dependency on all the other crates and re-exports them under a common namespace. Thanks to Rust conditional compilation,
          it is possible to conditionally include or exclude entire modules from the dependency tree via the mechanism of \texttt{cargo features}, making this
          crate a convenient tool to access all the framework functionalities in a single, configurable dependency.
\end{itemize}

\section{RuFi Core}

\subsection{RoundVM}
The listing \ref{lst:round_vm} shows the Round Virtual Machine, which is represented by a Rust struct that contains every dependency needed for executing its behavior.

\lstinputlisting[language=Rust, label={lst:round_vm}]{listings/round_vm.rs}

One of the most important functions of the RoundVM is the \textit{nest} function, which we can see in the listing \ref{lst:nest}.

\lstinputlisting[language=Rust, label={lst:nest}]{listings/nest.rs}

The nest function takes as the parameters:

\begin{itemize}
    \item \texttt{self}: a mutable reference to Self, the RoundVM;
    \item \texttt{slot}: the slot that should be written inside the Export;
    \item \texttt{expr}: an expression. In RuFi, expressions have the added parameter of a mutable reference to the RoundVM, since they may be language constructs, as will be later
          explained in this section;
    \item \texttt{write}: a boolean flag that determines if the value of the expression should be written in the Export.
    \item \texttt{inc}: a boolean flag that determines if the index of the AST's Slot in the VMStatus should be incremented.
\end{itemize}

The behavior of the function can be summarized as follows:

\begin{enumerate}
    \item push the slot onto the current Path in VMStatus;
    \item compute expr result;
    \item if write is true, check if the export has a value for the current path, if not, write the result to the export;
    \item if inc index is true, increment the index of the VMStatus (for ast navigation);
    \item return the expr result.
\end{enumerate}

\subsection{Language}
The first strategy that can come to mind for implementing the Language would be to have a Rust trait named ``Language'' that contains all the language constructs as methods, and then implement
it for the RoundVM via an \textit{impl Language for} block.

However, this approach has a major drawback: in fact, it clashes with Rust's borrowing rules.
The listing \ref{lst:bad_language} shows an erroneous attempt to implement the Language trait for the RoundVM.

\lstinputlisting[language=Rust, label={lst:bad_language}]{listings/bad_language.rs}

The code shown so far is valid Rust code, but when attempting to implement an aggregate program with this implementation, the flaws of this approach become evident, as
shown in the listing \ref{lst:bad_language_usage}.

\lstinputlisting[language=Rust, label={lst:bad_language_usage}]{listings/bad_language_usage.rs}

The problematic line of code is the last one when we try to pass an aggregate construct to the first nbr function. Since methods are not pure functions in Rust,
we need to pass a closure that captures the outer vm variable, on which we can then call another aggregate construct. However, in order for the vm variable to be
captured, it needs to implement the Copy trait, because the closure needs to have ownership of captured variables. Unfortunately, the RoundVM struct cannot implement the
Copy trait, since it contains the Export struct, which contains a HashMap that has a non-Copy type as a value:

\begin{lstlisting}
    pub struct Export {
        pub slots: HashMap<Path, Rc<Box<dyn Any>>>,
    }
\end{lstlisting}

Since the size of Any values cannot be known at compile-time, any structure that contains references to Any values cannot implement the Copy trait.
It is however possible for them to implement the Clone trait, via the smart pointer ``Rc''.

The code in the following listing will then compile:

\begin{lstlisting}
    let result = vm.nbr(|| vm.clone().nbr(|| 0));
\end{lstlisting}

However, this solution has a major problem: whenever a structure is cloned, the entire structure in memory is duplicated, meaning that every time the developer of an aggregate program
passes an aggregate construct to another, the memory footprint of the program will increase.

The proposed implementation utilizes another approach: each aggregate construct and built-in function is a pure Rust function that takes a mutable reference to the RoundVM as a parameter.
Each expression that can be passed to an aggregate construct would then need a mutable reference to the RoundVM as a parameter as well. In this way, we can combine aggregate constructs
without the need to copy or clone the RoundVM, making the code more memory-efficient. The listing \ref{lst:lang_impl} shows the current implementation of the Language.

\lstinputlisting[language=Rust, label={lst:lang_impl}]{listings/lang_impl.rs}

\section{RuFi Distributed}
The \texttt{rf-distributed} and \texttt{rf-distributed-impl} crates are responsible for realizing the distributed execution of RuFi programs. The first crate contains the definition of all the traits
that are needed for this purpose, such as Network, Mailbox and Time, as well as an implementation of the Platform since it is generic in those traits. The second crate contains an implementation of the traits
defined in the first crate. The choice of having two separate crates is because the implementation of some of the traits can be platform-specific. For example, the rf-distributed-impl crate
utilizes a popular MQTT library named Rumqtt \cite{005} to implement the Network trait. However, this library isn't compatible to all architectures. Other very popular and widely used, libraries like
the de-facto standard asynchronous runtime Tokio \cite{004} aren't fully compatible with the entirety of devices architectures. As such, the rf-distributed-impl crate is separated
from the rf-distributed crate so it can be replaced with a different implementation if needed.

\subsection{Networking}
One of the key abstractions that are present in RuFi Distributed is the \texttt{Network} trait. This trait is responsible for providing the logic by which devices can send and
receive messages through the network. The listing \ref{lst:network} shows the definition of the Network trait.

\lstinputlisting[language=Rust, label={lst:network}]{listings/network.rs}

The strategy chosen to implement this trait is to have a struct that contains a rumqttc-based MQTT Client and wraps it to adhere to the trait. Upon creation, the struct will
setup the MQTT Client and spawn a new thread that will handle incoming messages, which will need to be ``sent'' back to the Network's thread.

In Rust, there are two ways for threads to communicate and share information, the first one of which is through the \texttt{message passing} paradigm. The main idea is represented by
the slogan ``Do not communicate by sharing memory; instead, share memory by communicating''. To achieve this, Rust provides an implementation of the \textit{channel} abstraction,
which is a general programming concept by which data is sent from one thread to another. Channels have two halves:

\begin{itemize}
    \item \textit{Sender}: a cloneable type that can be used to send messages to the channel.
    \item \textit{Receiver}: a cloneable type that receives messages from the channel.
\end{itemize}

The usage of the channel abstraction is shown in the listing \ref{lst:channel}.

\lstinputlisting[language=Rust, label={lst:channel}]{listings/channels.rs}

So if we were to implement the communication between threads this way, the sender half of the channel would be passed to the thread that handles incoming messages (the ``handler thread''), and the receiver half will
remain inside the Network instance to be used by client code to retrieve the messages (the ``client thread''). Whenever a packet is received from the handler thread, it will be sent to the receiver half of the channel.

However, this approach has some drawbacks:

\begin{enumerate}
    \item the receiver half of the channel needs to be actively polled to retrieve the messages;
    \item the channel is not bidirectional. This means that the handler thread cannot store the messages and send them all at once on demand.
\end{enumerate}

These drawbacks combined mean that the client thread would need to busy wait for a single message from the network at every execution cycle, so the proposed implementation
utilizes a second approach: \texttt{shared state concurrency}. This is a programming paradigm that allows multiple threads to access the same shared state, and in Rust, it is done
via the \textit{Mutex} abstraction. This way, the handler thread can directly and atomically push the incoming messages to the shared state upon arrival, and the client thread can request
them all at once from the Network in a single call. Although programming concurrency through mutexes is generally avoided, especially in high-level languages, due to the complexity it can bring
to the program, in this case, the mutex logic is confined to a relatively small portion of the code and is not exposed to the client, so it has been chosen as a valid option.

The implementation for the Network trait exposed in the rf-distributed-impl crate is the one in the listing \ref{lst:network_impl}.

\lstinputlisting[language=Rust, label={lst:network_impl}]{listings/network_impl.rs}

\section{RuFi Gradient}
The RuFi Gradient crate contains an important example of what an aggregate program in RuFi can be and what it looks like. Since one of the core premises of \ac{fc} is to
provide key and reusable building blocks for aggregate computations, an aggregate program is nothing more than a function that combines these building blocks to achieve the
desired behavior. The aggregate program could then be used as a building block in a larger aggregate program, and so on.

The listing \ref{lst:rufi_gradient} shows the implementation of the RuFi Gradient aggregate program:

\lstinputlisting[language=Rust, label={lst:rufi_gradient}]{listings/rufi_gradient.rs}

The core functions used in this program are:

\begin{itemize}
    \item \textit{rep}: the operator that denotes a dynamically changing field;
    \item \textit{mux}: a branch variant that computes both the branches and returns the result of the branch that is selected by the condition. Since both branches of the operators
          are executed by the device, this construct does not restrict the domain like the \textit{branch} operator. Instead, it is used for simple conditional expressions;
    \item \textit{foldhood plus}: a variant of the foldhood operator that excludes the device from its neighborhood.
\end{itemize}

The \textit{is source} function calls the Virtual Machine and reads a sensor that establishes if the device is a source.
The aggregate program itself is a rep operation that has an initial value for the distance d equal to $0.0$.
Then, inside the repetition, there is a \textit{mux} call that returns a value of $0.0$ if the device is a source or else an aggregation between neighboring values is performed via the \textit{foldhood plus} builtin, resulting in the minimum distance $d + 1.0$ being kept as a result of the whole computation.
In this way, the immediate neighbors of the source will compute a value of $0.0 + 1.0$, and the neighbors of the neighbors will compute $1.0 + 1.0$, and so on.
For non-source devices that are not indirect neighbors of the source, the final result will be the starting value for the foldhood operator of $f64::INFINITY$.

\section{Macro-based DSL}
One of the objectives of the RuFi project is to provide a user-friendly and high-level DSL for writing aggregate programs. However, due to the Rust language's syntax, the current DSL isn't as user-friendly and
easily readable as the \ac{scafi} DSL: in fact, the developer of aggregate programs in \ac{rufi} needs to write a lot more boilerplate code, mainly due to the RoundVM dependency of the core constructs and the absence of high-level 
mechanisms like self-types and implicit parameters.
The listing \ref{lst:rufi_gradient} highlights this issue, as there are many instances where we explicitly pass a RoundVM reference to an expression.
To address this issue, we implemented a set of declarative macros that can be used instead of the core constructs and expands to a closure that takes a RoundVM reference as a parameter and passes it to a core construct like in the following listing:

\begin{lstlisting}[language=Rust]
    #[macro_export]
    macro_rules! rep {
        ($init:expr, $fun:expr) => {{
            |vm| rep(vm, $init, $fun)
        }};
    }
\end{lstlisting}

The listing \ref{lst:lst:rufi_gradient_macro} shows how we can avoid some boilerplate code by using the macros instead of the core constructs when possible.

\lstinputlisting[language=Rust, label={lst:lst:rufi_gradient_macro}]{listings/rufi_gradient_macros.rs}